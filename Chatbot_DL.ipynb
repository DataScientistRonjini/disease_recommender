{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "HB.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndwhKfwRvj5K",
        "outputId": "0877f810-ccb2-4827-abf5-20317b119733"
      },
      "source": [
        "import os\n",
        "import time\n",
        "x=!nvidia-smi\n",
        "count=0\n",
        "for i in x:\n",
        "    if \"============\" in i:\n",
        "        count+=1\n",
        "        break\n",
        "    count+=1\n",
        "if 'p100' in x[count].lower():\n",
        "    print(\"found\")\n",
        "else:\n",
        "    print(x[count])\n",
        "    time.sleep(1)\n",
        "    #os._exit(00)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4K89FgpCv41N",
        "outputId": "030d556d-c8b9-45f4-d274-6369a31e3793"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Jul 17 17:11:11 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKjBP06Pk2AG",
        "outputId": "ca1a232a-5fef-43bc-f821-9e94fe3662c0"
      },
      "source": [
        "pip install tflearn"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tflearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/3c/0b156d08ef3d4e2a8009ecab2af1ad2e304f6fb99562b6271c68a74a4397/tflearn-0.5.0.tar.gz (107kB)\n",
            "\r\u001b[K     |███                             | 10kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 20kB 27.6MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 30kB 32.5MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 40kB 33.6MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 51kB 33.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 61kB 34.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 71kB 30.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 81kB 30.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 92kB 31.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 102kB 32.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 32.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tflearn) (7.1.2)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tflearn: filename=tflearn-0.5.0-cp37-none-any.whl size=127300 sha256=5781ad863df79ef18f43932ea5d6aa33fa70d2c8da01b8b057eb8b0a3f7a0465\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/d2/ed/fb9a0d301dd9586c11e9547120278e624227f22fd5f4baf744\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJSJuq3-ki8U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6b0277b-6b5c-4f25-c25f-edb6cb87d796"
      },
      "source": [
        "#Used in Tensorflow Model\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tflearn\n",
        "import random\n",
        "\n",
        "#Usde to for Contextualisation and Other NLP Tasks.\n",
        "import nltk\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "stemmer = LancasterStemmer()\n",
        "\n",
        "#Other\n",
        "import json\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3xsmw-5j4wW",
        "outputId": "98e1aa8a-af24-44c9-a235-c2d874640d85"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEOpU4mnkx0n"
      },
      "source": [
        "with open('/content/Symtoms_intent.json') as json_data:\n",
        "    intents = json.load(json_data)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGsFNl-PlfeO",
        "outputId": "0a52aba0-61f1-45b9-de78-202b40530b4a"
      },
      "source": [
        "words = []\n",
        "classes = []\n",
        "documents = []\n",
        "ignore_words = ['?']\n",
        "print(\"Looping through the Intents to Convert them to words, classes, documents and ignore_words.......\")\n",
        "for intent in intents['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        # tokenize each word in the sentence\n",
        "        w = nltk.word_tokenize(pattern)\n",
        "        # add to our words list\n",
        "        words.extend(w)\n",
        "        # add to documents in our corpus\n",
        "        documents.append((w, intent['tag']))\n",
        "        # add to our classes list\n",
        "        if intent['tag'] not in classes:\n",
        "            classes.append(intent['tag'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looping through the Intents to Convert them to words, classes, documents and ignore_words.......\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtmRMscbmfe1",
        "outputId": "aeb1bac9-4ea7-4947-ed39-4c5684cae4e5"
      },
      "source": [
        "print(\"Stemming, Lowering and Removing Duplicates.......\")\n",
        "words = [stemmer.stem(w.lower()) for w in words if w not in ignore_words]\n",
        "words = sorted(list(set(words)))\n",
        "\n",
        "# remove duplicates\n",
        "classes = sorted(list(set(classes)))\n",
        "\n",
        "print (len(documents), \"documents\")\n",
        "print (len(classes), \"classes\", classes)\n",
        "print (len(words), \"unique stemmed words\", words)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stemming, Lowering and Removing Duplicates.......\n",
            "2240 documents\n",
            "273 classes [' Kala-azar/ Leishmaniasis', ' Ligneous Conjunctivitis', ' Low Vision and VisuaI Aids', ' Lymphoedema', ' Pellucid Marginal Degeneration', ' Pharyngoconjunctival Fever ', ' Phlyctenular Keratoconjunctivitis ', ' Pneumonia ', ' Polycystic ovary syndrome (PCOS) ', ' Post-herpetic neuralgia', ' Postpartum haemorrhage', ' Preeclampsia', ' Premenstrual syndrome', ' Presbyopia', ' Puerperal sepsis', ' lactose intolerance', 'Abdominal Pain symptoms', 'Abducens nerve Palsy', 'Abnormal uterine bleeding', 'Acquired Capillary Haemangioma of Eyelid', 'Acquired Immuno Deficiency Syndrome symptoms', 'Acute encephalitis syndrome', 'Adult Inclusion Conjunctivitis', 'Airbag Eye Injury', 'Alcohol Abuse and Alcoholism symptoms', 'Alopecia (hair loss) symptoms', \"Alzheimer's Disease symptoms\", 'Amaurosis Fugax', 'Amblyopia', 'Amoebiasis', 'Anaemia during pregnancy (Maternal anemia)', 'Anaemia symptoms', 'Aniseikonia', 'Anisometropia', 'Ankyloblepharon', 'Antepartum hemorrhage (Bleeding in late pregnancy)', 'Anthrax', 'Anxiety symptoms', 'Aphakia', 'Appendicitis symptoms', 'Arthritis', 'Asbestos-related diseases', 'Asthma', 'Astigmatism', 'Atherosclerosis', 'Atopic Keratoconjunctivitis', 'Autism symptoms', 'Avian influenza in humans', 'Back Pain symptoms', 'Bad breath (halitosis) symptoms', 'Band Shaped Keratopathy symptoms', 'Bedsores symptoms', \"Bell's Palsy symptoms\", 'Benign Essential Blepharospasm symptoms', 'Blepharitis symptoms', 'Blepharochalasis symptoms', 'Brain Tumour symptoms', 'Breast Cancer symptoms', 'Bronchitis symptoms', 'Brucellosis symptoms', 'Bruxism (Teeth Grinding) symptoms', 'Burns symptoms', 'COVID-19', 'Carpal Tunnel Syndrome', 'Cavernous Haemangioma of Eyelid', 'Cavities', 'Cervical cancer', 'Chalazion', 'Chalcosis', 'Chickenpox', 'Chikungunya Fever', 'Childhood Exotropia', 'Cholera', 'Chronic obstructive pulmonary disease (COPD)', 'Cleft Lip and Cleft Palate', 'Colorectal Cancer', 'Commotio Retinae', 'Computer Vision Syndrome', 'Congenital Capillary Haemangioma of Eyelid', 'Congenital anomalies (birth defects)', 'Conjunctival Concretions', 'Conjunctivochalasis', 'Corneal Abrasion', 'Coronary Heart Disease', 'Crimean-Congo haemorrhagic fever (CCHF)', 'Dacryoadenitis', 'Dacryocystitis', 'Dementia', 'Dengue Fever', 'Dermatochalasis', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diarrhea', 'Digit-Sucking', 'Diphtheria', 'Distichiasis', 'Double Elevator Palsy', \"Down's Syndrome\", 'Dracunculiasis', 'Duane Retraction Syndrome', 'Early pregnancy loss', 'Ebola Virus Disease (EVD)', 'Eclampsia', 'Ectopic pregnancy', 'Ectropion', 'Eczema', 'Endometriosis', 'Entropion', 'Epiblepharon', 'Epibulbar Dermoids', 'Epicanthus', 'Epidemic Keratoconjunctivitis', 'Epidemic dropsy', 'Epilepsy', 'Euryblepharon', 'Exposure Keratopathy', 'Eyelid Varix', 'Gaming disorder', 'Gangrene', 'Gastro-Esophageal Reflux Disease (GERD)', 'Giant Papillary Conjunctivitis', 'Glaucoma', 'Goitre', 'Gonorrhea', 'Guillain-Barré syndrome', 'Gum disease', 'Haemophilia', 'Hand, Foot and Mouth Disease', 'Heat-Related Illnesses and Heat waves', 'Helminthiasis', 'Hemangioma', 'Hepatitis', 'Herpes Simplex', 'Heterophoria', 'High risk pregnancy', 'Horner Syndrome', 'Human papillomavirus (HPV) infection and cervical cancer', 'Hypermetropia', 'Hypertension', 'Hypertensive Retinopathy', 'Hypervitaminosis A', 'Ichthyosis', 'Infertility', 'Inflammatory Bowel Disease', 'Insomnia', 'Intrauterine growth restriction (IUGR)', 'Iron Deficiency Anemia', 'Japanese Encephalitis', 'Jaundice', 'Keratoconus', 'Lagophthalmos', 'Leprosy', 'Leptospirosis', 'Leukemia', 'Lichen Planus', 'Lid Imbrication Syndrome', 'Madarosis symptoms', 'Malaria symptoms', 'Malocclusion symptoms', 'Mastitis symptoms', 'Measles(Khasra) symptoms', 'Meningitis symptoms', 'Microcephaly symptoms', 'Middle East respiratory syndrome coronavirus (MERS‐CoV) symptoms', 'Migraine symptoms', \"Mooren's Ulcer symptoms\", 'Mouth Breathing symptoms', 'Mouth Ulcers symptoms', 'Mucormycosis symptoms', 'Mumps symptoms', 'Myocardial Infarction (Heart Attack) symptoms', 'Myopia symptoms', 'Narcolepsy', 'Nasal Polyps', 'Neonatal Respiratory Disease Syndrome(NRDS)/Infant respiratory distress syndrome (IRDS)', 'Neuralgia', 'Nipah virus (NiV) infection', 'Obesity', 'Obsessive Compulsive Disorder', 'Ocular Graft-versus-host Disease', 'Oral Cancer', 'Orbital Cavernous Haemangioma', 'Orbital Dermoid', 'Orbital Fat Prolapse', 'Orbital Haemangiopericytoma', 'Orbital Lymphangioma', 'Orbital Solitary Fibrous Tumour', 'Orbital Varix', 'Osteoarthritis', 'Osteomyelitis', 'Osteoporosis', 'Otitis Media', \"Parkinson's Disease\", 'Perennial Allergic Conjunctivitis ', 'Pericarditis ', 'Photophthalmia', 'Pinguecula', 'Post Menopausal Bleeding', 'Postpartum depression/ Perinatal depression ', 'Psoriasis', 'Pterygium', 'Q Fever', 'Quinsy', 'Rabies', 'Ramsay-Hunt Syndrome', \"Raynaud's Phenomenon\", 'Recurrent Corneal Erosion Syndrome', 'Retinopathy of Prematurity', 'Rheumatic fever and rheumatic heart disease', 'Rubella', \"Salzmann's Nodular Degeneration\", 'Sarcoma', 'Scabies', 'Schizophrenia', 'Scrub Typhus', 'Scurvy ', 'Seasonal Allergic Conjunctivitis', 'Severe Acute Respiratory Syndrome (SARS)', 'Sexually transmitted infections (STIs)', 'Shaken Baby Syndrome', 'Siderosis Bulbi', 'Silicosis', 'Solar Retinopathy', 'Spheroidal Degeneration', 'Spinal cord Injury', 'Steatoblepharon', 'Stroke ', 'Sub-conjunctival Haemorrhage', 'Substance abuse', 'Superior Limbic Keratoconjunctivitis', 'Swine flu', 'Taeniasis/cysticercosis', \"Terrien's Marginal Degeneration\", 'Tetanus', 'Thalassemia', 'Thermal Injuries to the Eye', 'Toxic Keratoconjunctivitis', 'Trachoma', 'Trichiasis', 'Tuberculosis', 'Turners Syndrome', 'Ulcerative Colitis symptoms', 'Urticaria symptoms', 'Varicose Veins symptoms', 'Vernal Keratoconjunctivitis symptoms', 'Vitamin B12 Deficiency symptoms', 'Vitiligo symptoms', 'Welding-arc Maculopathy', 'West Nile fever', 'Whooping Cough/Pertussis', 'Xanthelasma', 'Xerophthalmia', 'Yaws', 'Yellow Fever', 'Zika Virus Disease', 'bleeding gums symptoms', 'bone fracture', 'cancer', 'factitious keratoconjunctivitis', 'female genital mutilation', 'fibroids', 'fibromyalgia', 'filamentary keratitis', 'filariasis', 'floppy eyelid syndrome', 'fluorosis', 'food poisoning', \"frey's syndrome\", 'frost bite', 'keratoglobus', 'papilloedema', 'sarcoidosis ', 'syphilis ']\n",
            "1745 unique stemmed words ['%', '&', \"'s\", '(', ')', ',', '-', '.', '/', '/past', '0.5', '1-2', '1-2minutes', '10', '100', '100-104°f', '100.4f', '100.4°f', '100.4ºf', '100.5°f', '101', '1040-1050', '105f', '12', '16', '18', '20', '24', '2cm/day', '30', '35', '36', '38', '38.3', '38.5ºc/for', '38c', '38°c', '38ºc', '40.6c', '400ml', '5', '65', '7gm/dl', '90', '90mm', '99°f', ':', ';', '<', '>', 'a', 'abdom', 'abdomin', 'abduc', 'abl', 'abnorm', 'abort', 'about', 'abov', 'abras', 'abs', 'accid', 'accompany', 'accum', 'ach', 'acid', 'acn', 'act', 'acu', 'acut', 'adapt', 'adduc', 'adenoid', 'adenomyos', 'adhd', 'adolesc', 'adult', 'adv', 'aerophob', 'affect', 'aft', 'afterim', 'ag', 'again', 'aggress', 'agit', 'air', 'airway', 'al', 'alcohol', 'alon', 'along', 'alopec', 'also', 'alt', 'alveol', 'amauros', 'amblyop', 'amenorrhoe', 'amount', 'an', 'anaem', 'and', 'and/or', 'andcough', 'anem', 'ang', 'angin', 'angl', 'anhidros', 'anisocor', 'anisometrop', 'ankl', 'ankyloblepharon', 'anophthalmo', 'anorex', 'answ', 'antery', 'anthrax', 'anticip', 'anxy', 'any', 'anywh', 'aort', 'apert', 'aphth', 'apne', 'apnoe', 'aponeuros', 'app', 'appear', 'appendix', 'appetit', 'approxim', 'ar', 'arch', 'are', 'area', 'arm', 'armpit', 'around', 'arterit', 'arthrit', 'as', 'ask', 'asleep', 'assocy', 'asthenop', 'asthm', 'astigm', 'asymptom', 'at', 'atax', 'atroph', 'attach', 'attack', 'attempt', 'attitud', 'attrit', 'autom', 'av', 'avert', 'avoid', 'awak', 'away', 'awkward', 'ax', 'axil', 'axilla', 'azotem', 'baby', 'back', 'backach', 'background', 'bact', 'bad', 'bag', 'bal', 'bald', 'be', 'becaus', 'becom', 'been', 'bef', 'begin', 'behavio', 'behavy', 'behind', 'being', 'bel', 'below', 'bend', 'benea', 'between', 'bev', 'bicuspid', 'bifid', 'bil', 'binocul', 'bir', 'bit', 'bitot', 'black', 'blad', 'bleb', 'blee', 'blench', 'blepharit', 'blepharophimos', 'blepharoptos', 'blepharospasm', 'blind', 'blink', 'blist', 'blister-like', 'blo', 'block', 'blood', 'bloody', 'blotchy', 'blu', 'bluish-purple', 'bluish-white', 'blur', 'blurry', 'body', 'bon', 'bond', 'book', 'born', 'both', 'bowel', 'bp', 'bradycard', 'brain', 'brea', 'breast', 'breast-feeding', 'breath', 'breathless', 'bridg', 'brief', 'bright', 'bright-red', 'broad', 'brok', 'bronz', 'brow', 'brown', 'bru', 'brush', 'brux', 'bucc', 'build', 'bulb', 'bulg', 'bulk', 'bump', 'burn', 'burrow', 'burst', 'but', 'buttock', 'by', 'c', 'caes', 'cal', 'calc', 'calv', 'can', 'canth', 'car', 'carbon', 'carbonac', 'cardiac', 'cardio-respiratory', 'cardiovascul', 'carry', 'cas', 'cataract', 'caus', 'cavern', 'cel', 'cent', 'cerebr', 'cerv', 'chalaz', 'chamb', 'chang', 'charact', 'cheek', 'cheilos', 'chem', 'chemos', 'chest', 'chew', 'chil', 'child', 'childr', 'chin', 'cholesterol', 'choroid', 'chromatopsia', 'chronic', 'circ', 'circul', 'circumf', 'clammy', 'clay', 'clear', 'cleft', 'clench', 'clos', 'close-up', 'clot', 'cloth', 'cloud', 'club', 'clumsy', 'co-ordination', 'coarct', 'coars', 'coat', 'cognit', 'col', 'cold', 'cold-like', 'collarbon', 'colo', 'color/', 'com', 'comfort', 'common', 'commotio', 'commun', 'comp', 'complain', 'complet', 'comply', 'compon', 'comput', 'concern', 'condit', 'confus', 'congenit', 'congest', 'conjunct', 'conjunctiv', 'conjunctivit', 'conscy', 'consist', 'const', 'constip', 'constrict', 'consum', 'cont', 'contact', 'contain', 'continu', 'contract', 'contrast', 'control', 'converg', 'convers', 'convuls', 'coordin', 'cop', 'cord', 'corn', 'corne', 'correct', 'correl', 'coryz', 'cosmet', 'cough', 'coughing-sometimes', 'could', 'cov', 'crack', 'cramp', 'crav', 'creas', 'cross', 'crowd', 'crust', 'cry', 'cur', 'curv', 'cut', 'cyanos', 'cyc', 'cyst', 'dai', 'dam', 'dandruff', 'dark', 'day', 'day-to-day', 'daytim', 'dea', 'dead', 'deaf', 'debilit', 'decid', 'decreas', 'deep', 'deeply', 'defec', 'defect', 'deficit/hyperactivity', 'deficy', 'deform', 'deg', 'degr', 'dehisc', 'dehydr', 'del', 'delay', 'delir', 'delivery', 'delud', 'dement', 'dent', 'dep', 'deposit', 'depress', 'dermatit', 'dermatochalas', 'desir', 'desquam', 'destin', 'destroy', 'detach', 'detect', 'detery', 'develop', 'diabet', 'diarrhe', 'diarrhoe', 'diastol', 'diff', 'differenty', 'difficul', 'difficult', 'digest', 'dil', 'dim', 'diminut', 'dimpl', 'diplop', 'dirty', 'dis', 'disappear', 'discharg', 'discol', 'discolo', 'discomfort', 'diseas', 'disfig', 'disord', 'displac', 'dist', 'distinct', 'distort', 'distract', 'distress', 'distribut', 'disturb', 'diverg', 'divid', 'dizzy', 'do', 'doe', 'doing', 'dom', 'doubl', 'doubt', 'douch', 'dow', 'down', 'downshoot', 'downward', 'drain', 'draught', 'draw', 'drench', 'drift', 'drink', 'drip', 'driv', 'drool', 'droop', 'drowsy', 'dry', 'duc', 'due', 'dur', 'dust', 'dysmorph', 'dysparuen', 'dysphag', 'dyspne', 'dyspnoe', 'e.g', 'e.g.', 'each', 'ear', 'earach', 'eas', 'easy', 'eat', 'ecc', 'ecchymos', 'echolal', 'ectrop', 'edem', 'edg', 'effect', 'efficy', 'effort', 'eight', 'eith', 'elbow', 'eld', 'elephantias', 'elev', 'elong', 'emot', 'empty', 'enamel', 'end', 'endocardit', 'energy', 'enjoy', 'enlarg', 'enough', 'entir', 'entrop', 'epicanth', 'epigastr', 'epilepsy', 'epiphor', 'episc', 'episod', 'epithel', 'er', 'erod', 'erupt', 'erythem', 'erythrops', 'es', 'esch', 'esotrop', 'espec', 'etc', 'ev', 'evalu', 'exacerb', 'exc', 'excess', 'excurs', 'excus', 'exerc', 'exert', 'exfo', 'expery', 'expir', 'expos', 'ext', 'extend', 'extr', 'extracon', 'extrem', 'exud', 'ey', 'eyebal', 'eyelash', 'eyelid', 'eyestrain', 'f', 'fac', 'facy', 'faded/discolor', 'faec', 'fail', 'failure-', 'faint', 'fal', 'famili', 'famy', 'fast', 'fat', 'fatig', 'fatigu', 'fear', 'feat', 'fec', 'fee', 'feel', 'feet', 'felt', 'female-', 'fet', 'fev', 'few', 'fibrin', 'fibros', 'field', 'fil', 'fila', 'fin', 'fing', 'fingernail', 'firm', 'first', 'fiss', 'fist', 'fit', 'fits/convulsion', 'fix', 'flak', 'flap', 'flar', 'flash', 'flat', 'fleet', 'flex', 'flo', 'floppy', 'floss', 'flu', 'flu-like', 'fluctu', 'fluid', 'fluorid', 'flush', 'foam', 'foc', 'focus', 'fold', 'follow', 'fontanel', 'food', 'foot', 'for', 'for10-20', 'forc', 'foreign', 'foreshort', 'foreskin', 'forget', 'form', 'foul', 'foul-smel', 'foul-smelling', 'found', 'fov', 'fract', 'fre', 'frequ', 'friend', 'from', 'front', 'fronto-temporal', 'ful', 'full-body', 'funct', 'fund', 'furth', 'fus', 'gain', 'gam', 'gas', 'gastro-esophageal', 'gastro-intestinal', 'gastrointestin', 'gaz', 'gbs', 'gen', 'genit', 'genital', 'gest', 'get', 'ghost', 'giant', 'giv', 'gland', 'glar', 'glass', 'glaucom', 'glob', 'glossit', 'go', 'grad', 'granulom', 'grat', 'gravid', 'gray', 'grayish-white', 'grayish-yellow', 'gre', 'green', 'grind', 'gritty', 'groin', 'groov', 'grow', 'growl', 'growth', 'grunt', 'guillain-barré', 'gum', 'gummy', 'gust', 'habit', 'haemangiom', 'haemangioma', 'haematur', 'haemoglobin', 'haemophil', 'haemoptys', 'haemorrh', 'haemosiderin', 'hair', 'hairlin', 'hairloss', 'hallucin', 'halo', 'hand', 'hap', 'hard', 'harm', 'harsh', 'has', 'hav', 'hb', 'head', 'head-turn', 'headach', 'heal', 'healthy', 'hear', 'heart', 'heartb', 'heartburn', 'heat', 'heavy', 'height', 'help', 'hepatit', 'her', 'herny', 'herpetiform', 'herself', 'heterochrom', 'hg', 'high', 'high-level', 'hip', 'his', 'his/her', 'hist', 'histiocyt', 'hiv', 'hoard', 'hoars', 'hol', 'hold', 'hopeless', 'horizont', 'hormon', 'hort', 'hostil', 'hot', 'hour', 'howev', 'hump', 'hungry', 'hurt', 'hydrocephal', 'hydrop', 'hydrophob', 'hygy', 'hyper-pigmentation', 'hyper-reflexia', 'hyperact', 'hypercholesterolem', 'hyperlipidaem', 'hypermetrop', 'hyperplas', 'hyperreflex', 'hypertend', 'hypertroph', 'hyphaem', 'hypo', 'hypotherm', 'hypothyroid', 'hypotony', 'ic', 'if', 'il', 'illumin', 'im', 'impair', 'import', 'improv', 'in', 'inact', 'inappropry', 'includ', 'incomplet', 'incontin', 'increas', 'index', 'indiffér', 'indo', 'induc', 'inf', 'infect', 'infecty', 'infertil', 'infilt', 'inflam', 'inform', 'inguin', 'inh', 'init', 'inject', 'injury', 'insid', 'insidy', 'insomn', 'inspir', 'insufficy', 'intens', 'intercours', 'interest', 'interf', 'intermit', 'intern', 'interrupt', 'interstit', 'intestin', 'into', 'intol', 'intracr', 'invert', 'involunt', 'involv', 'inward', 'iridodones', 'irregul', 'irrit', 'is', 'isol', 'it', 'itch', 'itchy', 'item', 'jaund', 'jaw', 'jerk', 'jerky', 'jet', 'joint', 'journey', 'joy', 'judg', 'just', 'keratin', 'keratit', 'keratoconjunctivit', 'keratomalac', 'keratopathy', 'kg/m2', 'kidney', 'kilogram', 'kne', 'know', 'koplik', 'lab', 'lack', 'lacrim', 'lagophthalmo', 'langu', 'larg', 'lassitud', 'last', 'lat', 'lay', 'lead', 'learn', 'left', 'leg', 'leiomyom', 'len', 'leng', 'lens', 'les', 'less', 'let', 'lethargy', 'leukocor', 'lev', 'level', 'levin', 'libido', 'lid', 'lid-to-pillow', 'lie', 'lif', 'lift', 'light', 'light-headedness', 'lik', 'limb', 'limit', 'lin', 'lip', 'lipid', 'littl', 'liv', 'loc', 'loch', 'lodg', 'long', 'longstand', 'look', 'loos', 'los', 'loss', 'lost', 'loud', 'low', 'low-grade', 'low-set', 'lump', 'lying', 'lymph', 'lymphadenopathy', 'lymphodem', 'maculopapul', 'mad', 'madaros', 'main', 'maint', 'mak', 'mala', 'malform', 'malign', 'malno', 'malnutrit', 'malocclud', 'malpres', 'manifest', 'margin', 'mark', 'mass', 'masset', 'mat', 'math', 'maxim', 'may', 'meas', 'mech', 'mecon', 'med', 'mellit', 'mem', 'memb', 'membr', 'meningit', 'meningoencephalit', 'menopaus', 'menst', 'menstru', 'ment', 'met', 'metamorphops', 'micocepha', 'microcys', 'microphthalmo', 'middl', 'midfac', 'might', 'migrain', 'mild', 'mileston', 'mim', 'min', 'minut', 'mios', 'mir', 'misalign', 'miscarry', 'misplac', 'miss', 'misshap', 'mix', 'mm', 'mobl', 'mod', 'monocul', 'month', 'mood', 'moody', 'mor', 'morn', 'mort', 'most', 'mot', 'motil', 'mottl', 'mou', 'mov', 'muc', 'much', 'muco-purulent', 'mucoid', 'mucopur', 'mucos', 'multipl', 'musc', 'musca', 'muscul', 'myalg', 'myocardit', 'myop', 'nail', 'nam', 'narrow', 'nas', 'nause', 'near', 'nearby', 'neck', 'necrot', 'nee', 'needl', 'neg', 'neovascul', 'nerv', 'neuropathy', 'new', 'next', 'night', 'night-time', 'nippl', 'nipple/s', 'no', 'nocturn', 'nod', 'nois', 'noisy', 'non', 'non-food', 'non-itchy', 'non-keratinised', 'non-painful', 'non-raised', 'nonverb', 'norm', 'nos', 'noseblee', 'nostril', 'not', 'numb', 'nyctalop', 'nystagm', 'obes', 'object', 'obl', 'obsc', 'obsess', 'obstet', 'obstruct', 'occ', 'occas', 'occupy', 'ocul', 'od', 'odo', 'oedem', 'oesophag', 'of', 'oft', 'oi', 'oligur', 'on', 'onlin', 'onset', 'ooz', 'op', 'opac', 'opaqu', 'opt', 'or', 'orbit', 'ord', 'org', 'oropharynx', 'osteoporos', 'oth', 'out', 'out-of-place', 'output', 'outward', 'ov', 'overact', 'overdos', 'overrid', 'oversleep', 'overwhelm', 'own', 'pad', 'pain', 'painless', 'pal', 'palm', 'palp', 'palpebr', 'palpebra', 'palpit', 'palsy', 'pancr', 'panoram', 'pap', 'papillom', 'parac', 'paraesthes', 'paralys', 'parasit', 'parch', 'parotid', 'paroxysm', 'part', 'partic', 'particul', 'pass', 'passageway', 'patch', 'patchy', 'path', 'pattern', 'paty', 'pay', 'peak', 'pelv', 'pen', 'peopl', 'perceiv', 'perf', 'perform', 'peri-orbital', 'period', 'periorbit', 'periph', 'perm', 'persist', 'person', 'perspir', 'petech', 'pharyngit', 'pharynx', 'phlegm', 'photophob', 'phrases', 'phylem', 'phys', 'pic', 'pierc', 'pig', 'pigeon', 'pin', 'pink', 'pit', 'plac', 'placent', 'plan', 'plaqu', 'plat', 'play', 'pleurit', 'plu', 'plur', 'pneumon', 'point', 'polyop', 'polyp', 'polypoid', 'poor', 'posit', 'post', 'postery', 'postmenopaus', 'postnas', 'pot', 'pow', 'pract', 'pre-auricular', 'prec', 'predict', 'predomin', 'preeclamps', 'pregn', 'prem', 'preoccup', 'pres', 'press', 'prev', 'prevy', 'prick', 'prickl', 'prim', 'problem', 'problems-', 'process', 'proclin', 'produc', 'profus', 'proglottid', 'progress', 'prolaps', 'prolong', 'promin', 'pron', 'pronouns', 'proptos', 'prost', 'protein', 'proteinur', 'protrud', 'prurit', 'pseudo-membrane', 'pseudoepicanth', 'pseudoesotrop', 'pseudoexotrop', 'pseudotrichias', 'psycholog', 'psychos', 'ptos', 'puck', 'puffy', 'pul', 'pulmon', 'puls', 'pulsatil', 'pulse-lik', 'punct', 'pupil', 'pur', 'purkind', 'purpl', 'pus', 'pyl', 'pyog', 'quest', 'quick', 'quit', 'rady', 'rainbow', 'rais', 'rang', 'rapid', 'rar', 'rash', 'rat', 'reach', 'react', 'read', 'real', 'reason', 'rec', 'recess', 'recogn', 'recov', 'rect', 'recur', 'red', 'red-blue', 'red-pink', 'reddish-purple', 'reduc', 'redund', 'reflux', 'refract', 'reg', 'regard', 'regurgit', 'rel', 'relax', 'reliev', 'rem', 'rememb', 'remov', 'rep', 'repetit', 'replac', 'reproduc', 'requir', 'resembl', 'respir', 'respons', 'rest', 'restless', 'restrict', 'result', 'retin', 'retina', 'retinoscop', 'retract', 'rewarm', 'rh', 'right', 'rigid', 'ring', 'ring-shaped', 'ris', 'risk', 'road', 'rock', 'rol', 'room', 'root', 'rop', 'rough', 'round', 'rout', 'routin', 'rudy', 'rumbl', 'run', 'runny', 'rupt', 's', 'sac', 'sad', 'saliv', 'sam', 'sca', 'scal', 'scalp', 'scar', 'school', 'scleral', 'scolios', 'scotom', 'scrotal', 'scrotum', 'seat', 'seborrhoe', 'second', 'secret', 'sed', 'see', 'seen', 'seg', 'seiz', 'sens', 'sensit', 'sep', 'sept', 'sery', 'sess', 'sev', 'sex', 'shak', 'shallow', 'shap', 'sharp', 'shield', 'shiv', 'shock', 'short', 'short-lived', 'should', 'show', 'shrinking', 'shrivel', 'sick', 'sid', 'sign', 'silicos', 'silv', 'simil', 'sin', 'sing', 'singl', 'sinus', 'sit', 'situ', 'siz', 'skelet', 'skil', 'skin', 'skin-picking', 'slant', 'sleep', 'sleepy', 'slight', 'slow', 'smal', 'smel', 'smil', 'smoo', 'sneez', 'snor', 'so', 'soak', 'soc', 'sock', 'soft', 'sol', 'solid', 'solv', 'som', 'somebody', 'someth', 'sometim', 'sor', 'sound', 'sour', 'sourc', 'spac', 'spasm', 'spasmod', 'spat', 'speak', 'spec', 'spectac', 'spee', 'speech', 'spend', 'spent', 'spid', 'spin', 'spleen', 'spont', 'spot', 'spread', 'spreading', 'spur', 'sput', 'squ', 'squint', 'stab', 'stag', 'stain', 'stand', 'star', 'start', 'stat', 'stay', 'steady', 'steatoblepharon', 'stenos', 'stereops', 'steril', 'stern', 'stick', 'sticky', 'stiff', 'stigm', 'stil', 'stimul', 'sting', 'stomach', 'stool', 'stoop', 'stop', 'strabismus', 'straightening', 'strain', 'straining', 'streaking', 'stress', 'stringy', 'stroke', 'strong', 'structures', 'stuffy', 'styl', 'subconjunct', 'subcut', 'suboptim', 'such', 'suck', 'sud', 'sudden-onset', 'suff', 'suggest', 'sulc', 'sunk', 'superf', 'superonas', 'superotemp', 'supery', 'supply', 'suppress', 'surfac', 'surgery', 'surround', 'suspect', 'swallow', 'swe', 'sweet', 'swel', 'swing', 'swol', 'symblepharon', 'symptom', 'syndrom', 'syphil', 'system', 'tachycard', 'tachypne', 'tak', 'talk', 'tapeworm', 'tars', 'task', 'tast', 'tb', 'tear', 'tearing/', 'tee', 'teeth-occlusal', 'telangiect', 'telangiectas', 'temp', 'temporomandibul', 'tend', 'tendon', 'tendonit', 'term', 'testic', 'testicul', 'tetan', 'than', 'that', 'the', 'their', 'them', 'then', 'ther', 'therm', 'thes', 'they', 'thi', 'thick', 'thigh', 'thin', 'thing', 'think', 'third', 'thirst', 'thirsty', 'thorax', 'though', 'thought', 'three', 'thrive', 'throat', 'throbbing', 'thrombophlebitis', 'thrombus', 'through', 'throughout', 'thrush', 'thumb', 'tic', 'tight', 'tilt', 'tim', 'ting', 'tingl', 'tint', 'tiny', 'tip', 'tir', 'tissu', 'to', 'toddl', 'toe', 'togeth', 'toilet', 'tol', 'ton', 'tongu', 'tonsil', 'too', 'toothach', 'top', 'tot', 'touch', 'toxin', 'track', 'tract', 'transy', 'trap', 'traum', 'travel', 'tre', 'trem', 'trembl', 'tri', 'trichotilloman', 'trism', 'troubl', 'trunk', 'try', 'tuberculos', 'tumo', 'turn', 'twin', 'twist', 'twitch', 'two', 'tymp', 'typ', 'ulc', 'ultim', 'umbl', 'un', 'un-wellness', 'unacceiv', 'uncomfort', 'unconcern', 'unconscy', 'uncontrol', 'und', 'undernea', 'understand', 'unev', 'unexplain', 'unil', 'unint', 'unintend', 'unknown', 'unpleas', 'unpredict', 'unrel', 'unsaf', 'unus', 'unwel', 'up', 'upon', 'upset', 'upshoot', 'upside-down', 'upward', 'urg', 'urin', 'urticar', 'us', 'uter', 'uterin', 'uveit', 'vagin', 'vaginos', 'vagu', 'valv', 'varix', 'vary', 'vascul', 'vasculit', 'vein', 'ven', 'vent', 'vers', 'vert', 'vertigo', 'very', 'vessel', 'vic', 'video', 'view', 'viol', 'vis', 'vit', 'vitamin', 'vitreo-retinal', 'vkc', 'voic', 'volit', 'volum', 'vomit', 'vulv', 'waist', 'wak', 'wal', 'walk', 'warm', 'wart', 'wast', 'wat', 'watery', 'waxy-looking', 'way', 'weak', 'wear', 'weary', 'weath', 'wedge-shaped', 'week', 'weight', 'well-circumscribed', 'well-rested', 'whe', 'wheez', 'when', 'wher', 'which', 'whil', 'whit', 'whizz', 'whoop', 'wid', 'wil', 'wind', 'with', 'withdraw', 'within', 'without', 'wom', 'word', 'work', 'worm', 'worm/', 'worry', 'wors', 'wound', 'wrinkl', 'xerophthalm', 'year', 'yellow', 'yellow-', 'yo', 'you', 'young', '–', '‘', '’', '“', '”']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGsJUqJCm80k",
        "outputId": "a9f4d3b2-23bd-4dee-837f-4f1555a603fa"
      },
      "source": [
        "print(\"Creating the Data for our Model.....\")\n",
        "training = []\n",
        "output = []\n",
        "print(\"Creating an List (Empty) for Output.....\")\n",
        "output_empty = [0] * len(classes)\n",
        "\n",
        "print(\"Creating Traning Set, Bag of Words for our Model....\")\n",
        "for doc in documents:\n",
        "    # initialize our bag of words\n",
        "    bag = []\n",
        "    # list of tokenized words for the pattern\n",
        "    pattern_words = doc[0]\n",
        "    # stem each word\n",
        "    pattern_words = [stemmer.stem(word.lower()) for word in pattern_words]\n",
        "    # create our bag of words array\n",
        "    for w in words:\n",
        "        bag.append(1) if w in pattern_words else bag.append(0)\n",
        "\n",
        "    # output is a '0' for each tag and '1' for current tag\n",
        "    output_row = list(output_empty)\n",
        "    output_row[classes.index(doc[1])] = 1\n",
        "\n",
        "    training.append([bag, output_row])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating the Data for our Model.....\n",
            "Creating an List (Empty) for Output.....\n",
            "Creating Traning Set, Bag of Words for our Model....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wxkq47c2nDOc",
        "outputId": "0c50ff2c-640e-44b9-c8d7-a1c3b7cc3ed0"
      },
      "source": [
        "print(\"Shuffling Randomly and Converting into Numpy Array for Faster Processing......\")\n",
        "random.shuffle(training)\n",
        "training = np.array(training)\n",
        "\n",
        "print(\"Creating Train and Test Lists.....\")\n",
        "train_x = list(training[:,0])\n",
        "train_y = list(training[:,1])\n",
        "print(\"Building Neural Network for Out Chatbot to be Contextual....\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shuffling Randomly and Converting into Numpy Array for Faster Processing......\n",
            "Creating Train and Test Lists.....\n",
            "Building Neural Network for Out Chatbot to be Contextual....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCDtcup1nJF3",
        "outputId": "8b309f4b-4838-4e47-a162-24a64a9ef95b"
      },
      "source": [
        "from tensorflow.python.framework import ops\n",
        "ops.reset_default_graph()\n",
        "print(\"Resetting graph data....\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Resetting graph data....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm0TNZUzoTcy",
        "outputId": "a8c86886-38a3-4299-ce10-e717d53fdebe"
      },
      "source": [
        "net = tflearn.input_data(shape=[None, len(train_x[0])])\n",
        "net = tflearn.fully_connected(net, 8)\n",
        "net = tflearn.fully_connected(net, 8)\n",
        "net = tflearn.fully_connected(net, len(train_y[0]), activation='softmax')\n",
        "net = tflearn.regression(net)\n",
        "print(\"Training....\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tflearn/initializations.py:165: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "Training....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mcqwKLeoYOU"
      },
      "source": [
        "model = tflearn.DNN(net, tensorboard_dir='tflearn_logs')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zJue52It8zw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5e9eed1-c275-4767-e444-4158880542ab"
      },
      "source": [
        "print(\"Training the Model.......\")\n",
        "model.fit(train_x, train_y, n_epoch=500, batch_size=8, show_metric=True)\n",
        "print(\"Saving the Model.......\")\n",
        "model.save('model.tflearn')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Step: 111866  | total loss: \u001b[1m\u001b[32m0.77123\u001b[0m\u001b[0m | time: 0.917s\n",
            "\u001b[2K\r| Adam | epoch: 400 | loss: 0.77123 - acc: 0.7333 -- iter: 1168/2240\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSiYuHFcoisQ"
      },
      "source": [
        "print(\"Pickle is also Saved..........\")\n",
        "pickle.dump( {'words':words, 'classes':classes, 'train_x':train_x, 'train_y':train_y}, open( \"training_data\", \"wb\" ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DW2eFy8oxd7"
      },
      "source": [
        "print(\"Loading Pickle.....\")\n",
        "data = pickle.load( open( \"training_data\", \"rb\" ) )\n",
        "words = data['words']\n",
        "classes = data['classes']\n",
        "train_x = data['train_x']\n",
        "train_y = data['train_y']\n",
        "\n",
        "\n",
        "with open('intents.json') as json_data:\n",
        "    intents = json.load(json_data)\n",
        "    \n",
        "print(\"Loading the Model......\")\n",
        "# load our saved model\n",
        "model.load('./model.tflearn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8woy7Tbjo8Kz"
      },
      "source": [
        "def clean_up_sentence(sentence):\n",
        "    # It Tokenize or Break it into the constituents parts of Sentense.\n",
        "    sentence_words = nltk.word_tokenize(sentence)\n",
        "    # Stemming means to find the root of the word.\n",
        "    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n",
        "    return sentence_words\n",
        "\n",
        "# Return the Array of Bag of Words: True or False and 0 or 1 for each word of bag that exists in the Sentence\n",
        "def bow(sentence, words, show_details=False):\n",
        "    sentence_words = clean_up_sentence(sentence)\n",
        "    bag = [0]*len(words)\n",
        "    for s in sentence_words:\n",
        "        for i,w in enumerate(words):\n",
        "            if w == s:\n",
        "                bag[i] = 1\n",
        "                if show_details:\n",
        "                    print (\"found in bag: %s\" % w)\n",
        "    return(np.array(bag))\n",
        "\n",
        "ERROR_THRESHOLD = 0.25\n",
        "print(\"ERROR_THRESHOLD = 0.25\")\n",
        "\n",
        "def classify(sentence):\n",
        "    # Prediction or To Get the Posibility or Probability from the Model\n",
        "    results = model.predict([bow(sentence, words)])[0]\n",
        "    # Exclude those results which are Below Threshold\n",
        "    results = [[i,r] for i,r in enumerate(results) if r>ERROR_THRESHOLD]\n",
        "    # Sorting is Done because heigher Confidence Answer comes first.\n",
        "    results.sort(key=lambda x: x[1], reverse=True)\n",
        "    return_list = []\n",
        "    for r in results:\n",
        "        return_list.append((classes[r[0]], r[1])) #Tuppl -> Intent and Probability\n",
        "    return return_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-afsFcCkpXDg"
      },
      "source": [
        "def response(sentence, userID='123', show_details=False):\n",
        "    results = classify(sentence)\n",
        "    # That Means if Classification is Done then Find the Matching Tag.\n",
        "    if results:\n",
        "        # Long Loop to get the Result.\n",
        "        while results:\n",
        "            for i in intents['intents']:\n",
        "                # Tag Finding\n",
        "                if i['tag'] == results[0][0]:\n",
        "                    # Random Response from High Order Probabilities\n",
        "                    return print(random.choice(i['responses']))\n",
        "\n",
        "            results.pop(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwymHWYQpcnh"
      },
      "source": [
        "while True:\n",
        "    input_data = input(\"You- \")\n",
        "    answer = response(input_data)\n",
        "    answer"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}